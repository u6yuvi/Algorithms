{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b9afd2f-097f-48d3-9eef-4d2ba0089d2d",
   "metadata": {},
   "source": [
    "# Numpy Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "578b68f2-8ec7-4e9b-8c5f-dc3399cddfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Input([No,of observations,Number of features]): (4, 3)\n",
      "Shape of Target Output ([No,of observations,Number of neuron in output layer]):(4, 1)\n",
      "Shape of Weight Matrix for Input([No,of input features,Number of output features]): (3, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    " \n",
    "# sigmoid function\n",
    "\n",
    "def nonlin(x,deriv=False):\n",
    "\n",
    "    if(deriv==True):\n",
    "\n",
    "        return x*(1-x)\n",
    "\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    " \n",
    "\n",
    "# input dataset\n",
    "\n",
    "X = np.array([ [0,0,1],[0,1,1],[1,0,1],[1,1,1] ])\n",
    "print(f'Shape of Input([No,of observations,Number of features]): {X.shape}')\n",
    "# output dataset           \n",
    "y = np.array([[0,0,1,1]]).T\n",
    "print(f'Shape of Target Output ([No,of observations,Number of neuron in output layer]):{y.shape}')\n",
    " \n",
    "# seed random numbers to make calculation\n",
    "# deterministic (just a good practice)\n",
    "np.random.seed(1)\n",
    " \n",
    "# initialize weights randomly \n",
    "syn0 = np.random.random((3,1))\n",
    "print(f'Shape of Weight Matrix for Input([No,of input features,Number of output features]): {syn0.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee18cb7a-c48a-4532-9bc9-b8724173a229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output After Training:\n",
      "[[0.06867521]\n",
      " [0.05555872]\n",
      " [0.95508347]\n",
      " [0.94433134]]\n",
      "Actual Output:\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(5):\n",
    "\n",
    "    # forward propagation\n",
    "    l0 = X\n",
    "\n",
    "    l1 = nonlin(np.dot(l0,syn0))\n",
    "    #print(f'Output after {i+1} iteration(l1): {l1.shape}')\n",
    "    # how much did we miss?\n",
    "\n",
    "    l1_error = y - l1\n",
    "    #print(f'Error in each record(l1_error): {l1_error}')\n",
    "\n",
    "    # multiply how much we missed by the\n",
    "\n",
    "    # slope of the sigmoid at the values in l1\n",
    "    #print(f'Derivate after {i+1} iteration: {nonlin(l1,True)}')\n",
    "    l1_delta = l1_error * nonlin(l1,True)\n",
    "    #print(f'Nudge factor to each record(l1_delta): {l1_delta}')\n",
    "\n",
    "    # update weights\n",
    "    #print(l0.T.shape , l1_delta.shape)\n",
    "    syn0 += np.dot(l0.T,l1_delta)\n",
    "    #print(f'Weights after {i+1} iterations(syn0) :{syn0}')\n",
    "\n",
    "print(\"Output After Training:\")\n",
    "\n",
    "print(l1)\n",
    "\n",
    "print(f'Actual Output:\\n {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8194dc-c33f-4893-82bd-73d354c37811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 features,4 record\n",
    "# 1 output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a97891f4-f566-4b66-8a99-0443e3d1ed45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 3), (4, 1), (3, 1))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "y = np.array([[0,0,1,1]]).T\n",
    "w = np.random.random((3,1))\n",
    "b = np.random.random(1)\n",
    "x.shape,y.shape,w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "96e96612-55df-491c-a5ff-4e0429514ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss0: -0.013743207833137316\n",
      "Loss1: -0.013731495158920998\n",
      "Loss2: -0.01371981138260113\n",
      "Loss3: -0.013708156387188364\n",
      "Loss4: -0.013696530056349965\n",
      "Loss5: -0.013684932274405315\n",
      "Loss6: -0.013673362926320931\n",
      "Loss7: -0.013661821897706095\n",
      "Loss8: -0.013650309074807215\n",
      "Loss9: -0.013638824344505474\n",
      "[[0.03734394]\n",
      " [0.0300676 ]\n",
      " [0.9756196 ]\n",
      " [0.96967653]]\n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for i in range(epochs):\n",
    "    h1 = np.dot(x,w)\n",
    "    output = nonlin(h1)\n",
    "    #print(output.shape)\n",
    "    loss = y - output\n",
    "    if i // 10 ==0:\n",
    "        print(f'Loss{i}: {np.sum(np.squeeze(loss))}')\n",
    "    loss_delta = loss * nonlin(output,deriv=True)\n",
    "    #print(loss_delta.shape)\n",
    "    w+= np.dot(x.T,loss_delta)\n",
    "\n",
    "print(output)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4729b067-86b3-45d1-b1cf-14f22b74e184",
   "metadata": {},
   "source": [
    "# Pytorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a7c8ec44-b738-4f93-a7c6-1d90f8c2ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "52d2f708-229b-4810-8633-596f49af1ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "056ed14d-ba7f-4257-80b2-92e816b59734",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "454ba59c-ed32-4f3f-a32c-406260feb28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scale(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a73759cc-3b91-40b1-bf2e-07bd9d706365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ea9687fb-f9d0-4aa8-9290-f823322959f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train size: (120, 4)\n",
      "X test size: (30, 4)\n",
      "y train size: (120,)\n",
      "y test size: (30,)\n",
      "Counter({0: 42, 2: 41, 1: 37})\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(f'X train size: {X_train.shape}')\n",
    "print(f'X test size: {X_test.shape}')\n",
    "print(f'y train size: {y_train.shape}')\n",
    "print(f'y test size: {y_test.shape}')\n",
    "\n",
    "# Distribution of both classes are roughly equal using train_test_split function\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c8727f67-b233-414d-a9c2-c12cc7e19ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Accuracy: 35.0000 | Cost: 83.1777\n",
      "Epoch: 1 | Accuracy: 64.1667 | Cost: 53.8651\n",
      "Epoch: 2 | Accuracy: 64.1667 | Cost: 29.1477\n",
      "Epoch: 3 | Accuracy: 65.0000 | Cost: 8.0210\n",
      "Epoch: 4 | Accuracy: 65.0000 | Cost: -10.3593\n",
      "Epoch: 5 | Accuracy: 65.0000 | Cost: -26.6443\n",
      "Epoch: 6 | Accuracy: 65.0000 | Cost: -41.3176\n",
      "Epoch: 7 | Accuracy: 65.0000 | Cost: -54.7359\n",
      "Epoch: 8 | Accuracy: 65.0000 | Cost: -67.1630\n",
      "Epoch: 9 | Accuracy: 65.0000 | Cost: -78.7964\n",
      "Weights \n",
      " tensor([[ 0.5947],\n",
      "        [-0.2931],\n",
      "        [ 0.7068],\n",
      "        [ 0.7100]])\n",
      "Bias \n",
      " tensor([0.5349])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "num_features = X.shape[1]\n",
    "weights = torch.zeros(num_features, 1, dtype=torch.float32)\n",
    "bias = torch.zeros(1, dtype=torch.float32)\n",
    "\n",
    "X_train = torch.from_numpy(X_train).type(torch.float32)\n",
    "y_train = torch.from_numpy(y_train).type(torch.float32)\n",
    "\n",
    "for epoch in range(num_epochs):        \n",
    "    # 1. Forwardpropagation:\n",
    "    # 1a. Affine Transformation: z = \\theta x + b\n",
    "    z = torch.add(torch.mm(X_train, weights), bias)\n",
    "    # 2a. Sigmoid/Logistic Function: y_hat = 1 / (1 + e^{-z})\n",
    "    y_hat = 1. / (1. + torch.exp(-z))\n",
    "\n",
    "    # Backpropagation:\n",
    "    # 1. Calculate binary cross entropy \n",
    "    l = torch.mm(-y_train.view(1, -1), torch.log(y_hat)) - torch.mm((1 - y_train).view(1, -1), torch.log(1 - y_hat))\n",
    "\n",
    "    # 2. Calculate dl/dz\n",
    "    dl_dz = y_train - y_hat.view(-1)\n",
    "\n",
    "    # 2. Calculate partial derivative of cost w.r.t weights (gradients)\n",
    "    # dl_dw = dl_dz dz_dw = (y_hat - y)(x^T)\n",
    "    grad = torch.mm(X_train.transpose(0, 1), dl_dz.view(-1, 1))\n",
    "\n",
    "    # Gradient descent:\n",
    "    # update our weights and bias with our gradients\n",
    "    weights += learning_rate * grad\n",
    "    bias += learning_rate * torch.sum(dl_dz)\n",
    "\n",
    "    # Accuracy\n",
    "    total = y_hat.shape[0]\n",
    "    predicted = (y_hat > 0.5).float().squeeze()\n",
    "    correct = (predicted == y_train).sum()\n",
    "    acc = 100 * correct / total \n",
    "\n",
    "    # Print accuracy and cost\n",
    "    print(f'Epoch: {epoch} | Accuracy: {acc.item() :.4f} | Cost: {l.item() :.4f}')\n",
    "\n",
    "print(f'Weights \\n {weights.data}')\n",
    "print(f'Bias \\n {bias.data}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6ac3bec-4d81-4f7d-8b2d-9505e2772c89",
   "metadata": {},
   "source": [
    "#We will create a tensor with shape (1, 5), one row and five columns, that contains values randomly distributed according to the normal distribution with a mean of zero and standard deviation of one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34794828-8bfb-4f08-a8cb-c37ccbf86c5f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6549e45-cdfe-4406-8478-855f547220c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Inpout features:3\n"
     ]
    }
   ],
   "source": [
    "features = torch.randn(3,3)\n",
    "print(f'Number of Inpout features:{features.shape[1]}')\n",
    "y = torch.tensor([[0,0,1],[1,0,0],[0,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5cb32fc0-6774-4753-a140-de50b8eada69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9022090b-8bda-4b27-947d-c7d1cc2524f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3840d46f-228e-4a3d-bdb6-bbc9b684546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = features.shape[1]\n",
    "n_hidden = 2\n",
    "n_output = 1\n",
    "w1 = torch.randn(n_inputs,n_hidden)\n",
    "b1 = torch.randn(n_hidden)\n",
    "w2 = torch.randn(n_hidden,n_output)\n",
    "b2 = torch.randn(n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a7df4cd3-65c1-4ee5-96e1-7d561b169dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/1+ torch.exp(-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4161b9b8-0efe-48ca-85cc-966bf780bc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer activation tensor([[ 1.1420, 40.9133],\n",
      "        [ 1.0873,  1.1440],\n",
      "        [ 1.4069,  1.0214]])\n",
      "Output tensor([[8.9033e+23],\n",
      "        [2.5676e+01],\n",
      "        [2.9438e+01]])\n"
     ]
    }
   ],
   "source": [
    "h1 = sigmoid(torch.matmul(features,w1)+b1)\n",
    "print(f'Hidden Layer activation {h1}')\n",
    "out = sigmoid(torch.matmul(h1,w2)+b2)\n",
    "print(f'Output {out}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3599098b-3436-4136-a31e-b7a8bdd7c8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1660])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f9448c54-afdd-45a6-af99-185147a6b4fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [102], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out[\u001b[38;5;28mrange\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]),y]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "out[range(y.shape[0]),y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "114e6a6b-5ce0-43e6-a4cd-e65db1611df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    h1 = sigmoid(torch.matmul(features,w1)+b1)\n",
    "    h2 = torch.matmul(h1,w2)+b2\n",
    "    return h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236521dd-4b43-49cb-8afa-59083bdfec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fnc():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fcd02b3-8bf3-4105-94b5-58d6cbc2db2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out\u001b[38;5;241m.\u001b[39mgrad()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "lr = 0.5  # learning rate hyperparameter\n",
    "epochs = 2  # how many epochs to train for\n",
    "\n",
    "for epoch in range(epochs):  # loop over the data repeatedly\n",
    "    for ii in range((n - 1) // bs + 1):  # in batches of size bs, so roughly n / bs of them\n",
    "        start_idx = ii * bs  # we are ii batches in, each of size bs\n",
    "        end_idx = start_idx + bs  # and we want the next bs entires\n",
    "\n",
    "        # pull batches from x and from y\n",
    "        xb = x_train[start_idx:end_idx]\n",
    "        yb = y_train[start_idx:end_idx]\n",
    "\n",
    "        # run model\n",
    "        pred = model(xb)\n",
    "\n",
    "        # get loss\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        # calculate the gradients with a backwards pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update the parameters\n",
    "        with torch.no_grad():  # we don't want to track gradients through this part!\n",
    "            # SGD learning rule: update with negative gradient scaled by lr\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "\n",
    "            # ACHTUNG: PyTorch doesn't assume you're done with gradients\n",
    "            #          until you say so -- by explicitly \"deleting\" them,\n",
    "            #          i.e. setting the gradients to 0.\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd5696-bdf5-477c-ba41-a1b710074e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a551af-f5e7-470b-8ff1-ad3553fdf745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6c1813-d03b-4aac-9949-458d05febe10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584d0f3-4ef5-4291-9511-af8f0263ea41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
